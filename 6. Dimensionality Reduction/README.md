
# Dimensionality Reduction Techniques on Python
Welcome to the fifth part of my repository. In this part, we will talk about an algorithm called Naive Bayes Classifier which is an easy and straightforward application of the Bayes Theorem for classification.

## Contents:

**Dimensionality Reduction Techniques on Python - 1:** In this notebook, I introduce the main concept behind dimensionality reduction and most commonly used dimensionality reduction algorithm: Principal Component Analysis (PCA). I also introduce variants of PCA such as Incremental PCA and Kernel PCA.

**Dimensionality Reduction Techniques on Python - 2:** In the second notebook, we extend our idea of dimensionality reduction with non-linear dimensionality reduction. In this notebook, I introduce Linear Discriminant Analysis (LDA), Multidimensional Scaling (MDS), ISOMAP, t-Distributed Stochastic Neighbor Embedding (t-SNE), and a variant of t-SNE: FFT-accelerated Interpolation-based t-SNE (Flt-SNE).  

**Dimensionality Reduction Techniques on Python - 3:** In this notebook, I introduce the main concept and mathematics behind Naive Bayes algorithm and different Naive Bayes Classifier types that you can use on Python.

**Dimensionality Reduction Techniques on Python - 4:** In this notebook, I introduce the main concept and mathematics behind Naive Bayes algorithm and different Naive Bayes Classifier types that you can use on Python.


**Notes:** The `GridSearchCV()` and `RandomSearchCV()` results make the notebooks unnecessarily longer. Therefore, I deleted their outputs.
